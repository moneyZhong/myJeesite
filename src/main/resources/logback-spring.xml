<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <springProperty scope="context" name="module" source="spring.application.name" defaltValue = "jeesite"></springProperty>
    <springProperty scope="context" name="bootstrapServers" source="spring.kafka.bootstrap-servers" defaltValue="localhost:9092"></springProperty>
    <appender name="consoleLog" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <!--格式化输出（配色）：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符-->
            <pattern>%yellow(%d{yyyy-MM-dd HH:mm:ss}) %red([%thread]) %highlight(%-5level) %cyan(%logger{50}) - %magenta(%msg) %n
            </pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- kafka的appender配置 -->
    <appender name="kafka" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <encoder  class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>${module} | %d | %-5level| %logger{50} - %msg</pattern>
            <charset>utf8</charset>
        </encoder>
        <topic>log-stash</topic>
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"/>
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>

        <!-- Optional parameter to use a fixed partition -->
        <!-- <partition>0</partition> -->

        <!-- Optional parameter to include log timestamps into the kafka message -->
        <!-- <appendTimestamp>true</appendTimestamp> -->

        <!-- each <producerConfig> translates to regular kafka-client config (format: key=value) -->
        <!-- producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs -->
        <!-- bootstrap.servers is the only mandatory producerConfig -->
        <producerConfig>bootstrap.servers=localhost:9092</producerConfig>
        <producerConfig>retries=1</producerConfig>

        <producerConfig>batch-size=16384</producerConfig>
        <producerConfig>buffer-memory=33554432</producerConfig>
        <producerConfig>properties.max.request.size==2097152</producerConfig>
        <!-- 如果kafka不可用则输出到控制台 -->
        <appender-ref ref="consoleLog"/>

    </appender>
    <!--根据日志级别分离日志，分别输出到不同的文件-->
    <appender name="fileInfoLog" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>DENY</onMatch>
            <onMismatch>ACCEPT</onMismatch>
        </filter>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>
                %d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{50} - %msg%n
            </pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!--滚动策略-->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!--按时间保存日志 修改格式可以按小时、按天、月来保存-->
            <fileNamePattern>/var/opt/log/jeesite.info.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <!--保存时长(天)-->
            <MaxHistory>90</MaxHistory>
            <!--文件大小-->
            <totalSizeCap>4GB</totalSizeCap>
            <maxFileSize>500MB</maxFileSize>
        </rollingPolicy>
    </appender>

    <appender name="fileErrorLog" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>ERROR</level>
        </filter>
        <encoder>
            <pattern>
                %d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{50} - %msg%n
            </pattern>
        </encoder>
        <!--滚动策略-->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!--路径-->
            <fileNamePattern>/var/opt/log/jeesite.error.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <MaxHistory>90</MaxHistory>
            <!--文件大小-->
            <totalSizeCap>4GB</totalSizeCap>
            <maxFileSize>500MB</maxFileSize>
        </rollingPolicy>
    </appender>

    <!-- project default level -->
    <logger name="org.springframework" level="INFO"/>


    <springProfile name="dev">
        <!--打印SQL-->
        <logger name="com.wolfking.jeesite.modules.sys.dao" level="DEBUG"/>
        <root level="INFO">
            <appender-ref ref="consoleLog"/>
<!--            <appender-ref ref="kafka"/>-->
        </root>
    </springProfile>

    <springProfile name="test">
        <!--打印SQL-->
        <logger name="com.wolfking.jeesite.modules.sys.dao" level="DEBUG"/>
        <root level="INFO">
            <appender-ref ref="fileInfoLog"/>
            <appender-ref ref="fileErrorLog"/>
<!--            <appender-ref ref="kafka"/>-->
        </root>
    </springProfile>

    <springProfile name="prod">
        <root level="INFO">
            <appender-ref ref="fileInfoLog"/>
            <appender-ref ref="fileErrorLog"/>
<!--            <appender-ref ref="kafka"/>-->
        </root>
    </springProfile>

</configuration>